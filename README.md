# CoreML-Practice-with-SwiftUI

**This Project is IN PROGRESS **

This is a CoreML Practice with SwiftUI. Pretrained Models from [Apple CoreML Models](https://developer.apple.com/machine-learning/models/). 

![](apple-models.png)

## Included Demos

* **FCRN-DepthPrediction** [FCRN-DepthPrediction](https://github.com/iro-cp/FCRN-DepthPrediction): Predict the depth from a single image.
* **MNISTClassifier** [MNIST](http://yann.lecun.com/exdb/mnist/): Classify a single handwritten digit (supports digits 0-9).
* **ImageClassifier** 
  * [MobileNetV2](https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet): The MobileNetv2 architecture trained to classify the dominant object in a camera frame or image 、
  * [Resnet50](https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py): A Residual Neural Network that will classify the dominant object in a camera frame or image 、
  * [SqueezeNet](https://github.com/DeepScale/SqueezeNet): A small Deep Neural Network architecture that classifies the dominant object in a camera frame or image.
* **Object Detection** [YOLOv3](https://github.com/pjreddie/darknet): Locate and classify 80 different types of objects present in a camera frame or image.

## How to use 

